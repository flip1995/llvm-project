; NOTE: Assertions have been autogenerated by utils/update_test_checks.py
; RUN: opt -instcombine -S %s -o - -debug-only=instcombine,instsimplify
; RUN: opt -instcombine -S %s -o - | FileCheck %s -check-prefixes CHECK
target datalayout = "E-m:e-pf200:128:128:128:64-i8:8:32-i16:16:32-i64:64-n32:64-S128-A200-P200-G200"
target triple = "cheri-unknown-freebsd"

declare i64 @llvm.cheri.cap.diff.i64(i8 addrspace(200)*, i8 addrspace(200)*) addrspace(200) #1
declare i8 addrspace(200)* @llvm.cheri.cap.bounds.set.i64(i8 addrspace(200)*, i64) addrspace(200) #1
declare i8 addrspace(200)* @llvm.cheri.cap.bounds.set.exact.i64(i8 addrspace(200)*, i64) addrspace(200) #1
declare i8 addrspace(200)* @llvm.cheri.cap.address.set.i64(i8 addrspace(200)*, i64) addrspace(200) #1

declare void @use(i8 addrspace(200)*) addrspace(200) #1


define signext i32 @stack_int_inlined() local_unnamed_addr addrspace(200) #5 {
; CHECK-LABEL: @stack_int_inlined(
; CHECK-NEXT:  entry:
; CHECK-NEXT:    [[VALUE:%.*]] = alloca i32, align 4, addrspace(200)
; CHECK-NEXT:    [[TMP0:%.*]] = bitcast i32 addrspace(200)* [[VALUE]] to i8 addrspace(200)*
; CHECK-NEXT:    store i32 1, i32 addrspace(200)* [[VALUE]], align 4
; CHECK-NEXT:    [[TMP1:%.*]] = call i8 addrspace(200)* @llvm.cheri.cap.bounds.set.i64(i8 addrspace(200)* nonnull [[TMP0]], i64 4)
; CHECK-NEXT:    [[ADDRESS_WITH_BOUNDS:%.*]] = bitcast i8 addrspace(200)* [[TMP1]] to i32 addrspace(200)*
; CHECK-NEXT:    store i32 2, i32 addrspace(200)* [[ADDRESS_WITH_BOUNDS]], align 4
; CHECK-NEXT:    [[TMP2:%.*]] = load i32, i32 addrspace(200)* [[VALUE]], align 4
; CHECK-NEXT:    ret i32 [[TMP2]]
;
entry:
  %value = alloca i32, align 4, addrspace(200)
  %0 = bitcast i32 addrspace(200)* %value to i8 addrspace(200)*
  store i32 1, i32 addrspace(200)* %value, align 4
  %1 = call i8 addrspace(200)* @llvm.cheri.cap.bounds.set.i64(i8 addrspace(200)* nonnull %0, i64 4)
  %address.with.bounds = bitcast i8 addrspace(200)* %1 to i32 addrspace(200)*
  store i32 2, i32 addrspace(200)* %address.with.bounds, align 4
  %2 = load i32, i32 addrspace(200)* %value, align 4
  ret i32 %2
}

; Can't omit the bounds here:
define signext i32 @stack_int_inlined_escapes() local_unnamed_addr addrspace(200) #5 {
; CHECK-LABEL: @stack_int_inlined_escapes(
; CHECK-NEXT:  entry:
; CHECK-NEXT:    [[VALUE:%.*]] = alloca i32, align 4, addrspace(200)
; CHECK-NEXT:    [[TMP0:%.*]] = bitcast i32 addrspace(200)* [[VALUE]] to i8 addrspace(200)*
; CHECK-NEXT:    store i32 1, i32 addrspace(200)* [[VALUE]], align 4
; CHECK-NEXT:    [[TMP1:%.*]] = call i8 addrspace(200)* @llvm.cheri.cap.bounds.set.i64(i8 addrspace(200)* nonnull [[TMP0]], i64 4)
; CHECK-NEXT:    call void @use(i8 addrspace(200)* nonnull [[TMP1]])
; CHECK-NEXT:    [[ADDRESS_WITH_BOUNDS:%.*]] = bitcast i8 addrspace(200)* [[TMP1]] to i32 addrspace(200)*
; CHECK-NEXT:    store i32 2, i32 addrspace(200)* [[ADDRESS_WITH_BOUNDS]], align 4
; CHECK-NEXT:    [[TMP2:%.*]] = load i32, i32 addrspace(200)* [[VALUE]], align 4
; CHECK-NEXT:    ret i32 [[TMP2]]
;
entry:
  %value = alloca i32, align 4, addrspace(200)
  %0 = bitcast i32 addrspace(200)* %value to i8 addrspace(200)*
  store i32 1, i32 addrspace(200)* %value, align 4
  %1 = call i8 addrspace(200)* @llvm.cheri.cap.bounds.set.i64(i8 addrspace(200)* nonnull %0, i64 4)
  call void @use(i8 addrspace(200)* nonnull %1)
  %address.with.bounds = bitcast i8 addrspace(200)* %1 to i32 addrspace(200)*
  store i32 2, i32 addrspace(200)* %address.with.bounds, align 4
  %2 = load i32, i32 addrspace(200)* %value, align 4
  ret i32 %2
}

; Can omit bounds here since we know the original size
define signext i32 @used_by_smaller_setbounds() local_unnamed_addr addrspace(200) #5 {
; CHECK-LABEL: @used_by_smaller_setbounds(
; CHECK-NEXT:  entry:
; CHECK-NEXT:    [[VALUE:%.*]] = alloca i32, align 4, addrspace(200)
; CHECK-NEXT:    [[TMP0:%.*]] = bitcast i32 addrspace(200)* [[VALUE]] to i8 addrspace(200)*
; CHECK-NEXT:    store i32 1, i32 addrspace(200)* [[VALUE]], align 4
; CHECK-NEXT:    [[TMP1:%.*]] = call i8 addrspace(200)* @llvm.cheri.cap.bounds.set.i64(i8 addrspace(200)* nonnull [[TMP0]], i64 4)
; CHECK-NEXT:    call void @use(i8 addrspace(200)* nonnull [[TMP1]])
; CHECK-NEXT:    [[ADDRESS_WITH_BOUNDS:%.*]] = bitcast i8 addrspace(200)* [[TMP1]] to i32 addrspace(200)*
; CHECK-NEXT:    store i32 2, i32 addrspace(200)* [[ADDRESS_WITH_BOUNDS]], align 4
; CHECK-NEXT:    [[TMP2:%.*]] = load i32, i32 addrspace(200)* [[VALUE]], align 4
; CHECK-NEXT:    ret i32 [[TMP2]]
;
entry:
  %value = alloca i32, align 4, addrspace(200)
  %0 = bitcast i32 addrspace(200)* %value to i8 addrspace(200)*
  store i32 1, i32 addrspace(200)* %value, align 4
  %1 = call i8 addrspace(200)* @llvm.cheri.cap.bounds.set.i64(i8 addrspace(200)* nonnull %0, i64 4)
  call void @use(i8 addrspace(200)* nonnull %1)
  %address.with.bounds = bitcast i8 addrspace(200)* %1 to i32 addrspace(200)*
  store i32 2, i32 addrspace(200)* %address.with.bounds, align 4
  %2 = load i32, i32 addrspace(200)* %value, align 4
  ret i32 %2
}

; Must set bounds here since we would trap:
define signext i32 @used_by_out_of_bounds_load() local_unnamed_addr addrspace(200) #5 {
; CHECK-LABEL: @used_by_out_of_bounds_load(
; CHECK-NEXT:  entry:
; CHECK-NEXT:    [[VALUE:%.*]] = alloca i32, align 4, addrspace(200)
; CHECK-NEXT:    [[TMP0:%.*]] = bitcast i32 addrspace(200)* [[VALUE]] to i8 addrspace(200)*
; CHECK-NEXT:    store i32 1, i32 addrspace(200)* [[VALUE]], align 4
; CHECK-NEXT:    [[TMP1:%.*]] = call i8 addrspace(200)* @llvm.cheri.cap.bounds.set.i64(i8 addrspace(200)* nonnull [[TMP0]], i64 3)
; CHECK-NEXT:    [[ADDRESS_WITH_BOUNDS:%.*]] = bitcast i8 addrspace(200)* [[TMP1]] to i32 addrspace(200)*
; CHECK-NEXT:    store i32 2, i32 addrspace(200)* [[ADDRESS_WITH_BOUNDS]], align 4
; CHECK-NEXT:    [[TMP2:%.*]] = load i32, i32 addrspace(200)* [[VALUE]], align 4
; CHECK-NEXT:    ret i32 [[TMP2]]
;
entry:
  %value = alloca i32, align 4, addrspace(200)
  %0 = bitcast i32 addrspace(200)* %value to i8 addrspace(200)*
  store i32 1, i32 addrspace(200)* %value, align 4
  %1 = call i8 addrspace(200)* @llvm.cheri.cap.bounds.set.i64(i8 addrspace(200)* nonnull %0, i64 3) ; 3 < 4 -> load will trap
  %address.with.bounds = bitcast i8 addrspace(200)* %1 to i32 addrspace(200)*
  store i32 2, i32 addrspace(200)* %address.with.bounds, align 4
  %2 = load i32, i32 addrspace(200)* %value, align 4
  ret i32 %2
}
