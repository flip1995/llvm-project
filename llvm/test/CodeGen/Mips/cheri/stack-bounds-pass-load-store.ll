; NOTE: Assertions have been autogenerated by utils/update_test_checks.py
; The new CheriBoundedStackPseudo instruction lets us pretend that the incoffset+csetbounds
; is a single trivially rematerizable instruction so it can freely move it around to avoid stack spills.
; we were moving the allocation of the register that is only used later to the beginning

; REQUIRES: asserts
; RUN: %cheri_purecap_opt -cheri-bound-allocas %s -o - -S -cheri-stack-bounds=if-needed -debug-only=cheri-bound-allocas 2>%t.dbg | FileCheck %s
; RUN: FileCheck %s -input-file=%t.dbg -check-prefix DBG

target datalayout = "Eme-pf200:128:128:128:64-A200-P200-G200"

@global_leak = addrspace(200) global [16 x i32] addrspace(200)* zeroinitializer, align 16
@global_leak2 = addrspace(200) global i8 addrspace(200)* zeroinitializer, align 16


define void @store_stack_to_global() addrspace(200) nounwind {
; CHECK-LABEL: @store_stack_to_global(
; CHECK-NEXT:  entry:
; CHECK-NEXT:    [[X:%.*]] = alloca [16 x i32], align 4, addrspace(200)
; CHECK-NEXT:    [[TMP0:%.*]] = bitcast [16 x i32] addrspace(200)* [[X]] to i8 addrspace(200)*
; CHECK-NEXT:    [[TMP1:%.*]] = call i8 addrspace(200)* @llvm.cheri.bounded.stack.cap.i64(i8 addrspace(200)* [[TMP0]], i64 64)
; CHECK-NEXT:    [[TMP2:%.*]] = bitcast i8 addrspace(200)* [[TMP1]] to [16 x i32] addrspace(200)*
; CHECK-NEXT:    store [16 x i32] addrspace(200)* [[TMP2]], [16 x i32] addrspace(200)* addrspace(200)* @global_leak, align 16
; CHECK-NEXT:    ret void
;
entry:
  %x = alloca [16 x i32], align 4, addrspace(200)
  store [16 x i32] addrspace(200)* %x, [16 x i32] addrspace(200)* addrspace(200)* @global_leak, align 16
  ret void
}

; DBG-LABEL: Checking function store_stack_to_global
; DBG-NEXT: cheri-bound-allocas:  -Checking if load/store needs bounds (GEP offset is 0):   store [16 x i32] addrspace(200)* %x, [16 x i32] addrspace(200)* addrspace(200)* @global_leak, align 16
; DBG-NEXT: cheri-bound-allocas:   -Stack slot used as value and not pointer -> must set bounds
; DBG-NEXT: cheri-bound-allocas: Found alloca use that needs bounds:   store [16 x i32] addrspace(200)* %x, [16 x i32] addrspace(200)* addrspace(200)* @global_leak, align 16
; DBG-NEXT: cheri-bound-allocas: store_stack_to_global: 1 of 1 users need bounds for   %x = alloca [16 x i32], align 4, addrspace(200)
; DBG-NEXT: store_stack_to_global: setting bounds on stack alloca to 64  %x = alloca [16 x i32], align 4, addrspace(200)

define void @store_stack_to_global_with_offset() addrspace(200) nounwind {
; CHECK-LABEL: @store_stack_to_global_with_offset(
; CHECK-NEXT:  entry:
; CHECK-NEXT:    [[X:%.*]] = alloca [16 x i32], align 4, addrspace(200)
; CHECK-NEXT:    [[TMP0:%.*]] = bitcast [16 x i32] addrspace(200)* [[X]] to i8 addrspace(200)*
; CHECK-NEXT:    [[TMP1:%.*]] = call i8 addrspace(200)* @llvm.cheri.bounded.stack.cap.i64(i8 addrspace(200)* [[TMP0]], i64 64)
; CHECK-NEXT:    [[TMP2:%.*]] = bitcast i8 addrspace(200)* [[TMP1]] to [16 x i32] addrspace(200)*
; CHECK-NEXT:    [[X_I8:%.*]] = bitcast [16 x i32] addrspace(200)* [[TMP2]] to i8 addrspace(200)*
; CHECK-NEXT:    [[X_PLUS_4:%.*]] = getelementptr inbounds i8, i8 addrspace(200)* [[X_I8]], i32 4
; CHECK-NEXT:    store i8 addrspace(200)* [[X_PLUS_4]], i8 addrspace(200)* addrspace(200)* @global_leak2, align 16
; CHECK-NEXT:    ret void
;
entry:
  %x = alloca [16 x i32], align 4, addrspace(200)
  %x_i8 = bitcast [16 x i32] addrspace(200)* %x to i8 addrspace(200)*
  %x_plus_4 = getelementptr inbounds i8, i8 addrspace(200)* %x_i8, i32 4
  store i8 addrspace(200)* %x_plus_4, i8 addrspace(200)* addrspace(200)* @global_leak2, align 16
  ret void
}

; DBG-LABEL: Checking function store_stack_to_global_with_offset
; DBG-NEXT: cheri-bound-allocas:  -Checking if bitcast needs stack bounds:   %x_i8 = bitcast [16 x i32] addrspace(200)* %x to i8 addrspace(200)*
; DBG-NEXT: cheri-bound-allocas:   -Checking if getelementptr needs stack bounds:   %x_plus_4 = getelementptr inbounds i8, i8 addrspace(200)* %x_i8, i32 4
; DBG-NEXT: cheri-bound-allocas:    -Checking if load/store needs bounds (GEP offset is 4):   store i8 addrspace(200)* %x_plus_4, i8 addrspace(200)* addrspace(200)* @global_leak2, align 16
; DBG-NEXT: cheri-bound-allocas:     -Stack slot used as value and not pointer -> must set bounds
; DBG-NEXT: cheri-bound-allocas:   -Adding stack bounds since getelementptr user needs bounds:   store i8 addrspace(200)* %x_plus_4, i8 addrspace(200)* addrspace(200)* @global_leak2, align 16
; DBG-NEXT: cheri-bound-allocas:  -Adding stack bounds since bitcast user needs bounds:   %x_plus_4 = getelementptr inbounds i8, i8 addrspace(200)* %x_i8, i32 4
; DBG-NEXT: cheri-bound-allocas: Found alloca use that needs bounds:   %x_i8 = bitcast [16 x i32] addrspace(200)* %x to i8 addrspace(200)*
; DBG-NEXT: cheri-bound-allocas: store_stack_to_global_with_offset: 1 of 1 users need bounds for   %x = alloca [16 x i32], align 4, addrspace(200)
; DBG-NEXT: store_stack_to_global_with_offset: setting bounds on stack alloca to 64  %x = alloca [16 x i32], align 4, addrspace(200)
; DBG-EMPTY:

define [16 x i32] addrspace(200)* @store_stack_to_other_slot() addrspace(200) nounwind {
; CHECK-LABEL: @store_stack_to_other_slot(
; CHECK-NEXT:  entry:
; CHECK-NEXT:    [[SLOT_SRC:%.*]] = alloca [16 x i32], align 4, addrspace(200)
; CHECK-NEXT:    [[SLOT_LEAK:%.*]] = alloca [16 x i32] addrspace(200)*, align 16, addrspace(200)
; CHECK-NEXT:    [[TMP0:%.*]] = bitcast [16 x i32] addrspace(200)* [[SLOT_SRC]] to i8 addrspace(200)*
; CHECK-NEXT:    [[TMP1:%.*]] = call i8 addrspace(200)* @llvm.cheri.bounded.stack.cap.i64(i8 addrspace(200)* [[TMP0]], i64 64)
; CHECK-NEXT:    [[TMP2:%.*]] = bitcast i8 addrspace(200)* [[TMP1]] to [16 x i32] addrspace(200)*
; CHECK-NEXT:    store [16 x i32] addrspace(200)* [[TMP2]], [16 x i32] addrspace(200)* addrspace(200)* [[SLOT_LEAK]], align 16
; CHECK-NEXT:    [[LEAKED_VALUE:%.*]] = load [16 x i32] addrspace(200)*, [16 x i32] addrspace(200)* addrspace(200)* [[SLOT_LEAK]], align 16
; CHECK-NEXT:    ret [16 x i32] addrspace(200)* [[LEAKED_VALUE]]
;
entry:
  %slot_src = alloca [16 x i32], align 4, addrspace(200)
  %slot_leak = alloca [16 x i32] addrspace(200)*, align 16, addrspace(200)
  store [16 x i32] addrspace(200)* %slot_src, [16 x i32] addrspace(200)* addrspace(200)* %slot_leak, align 16
  %leaked_value = load [16 x i32] addrspace(200)*, [16 x i32] addrspace(200)* addrspace(200)* %slot_leak, align 16
  ret [16 x i32] addrspace(200)* %leaked_value
}

; DBG-LABEL: Checking function store_stack_to_other_slot
; DBG-NEXT: cheri-bound-allocas:  -Checking if load/store needs bounds (GEP offset is 0):   store [16 x i32] addrspace(200)* %slot_src, [16 x i32] addrspace(200)* addrspace(200)* %slot_leak, align 16
; DBG-NEXT: cheri-bound-allocas:   -Stack slot used as value and not pointer -> must set bounds
; DBG-NEXT: cheri-bound-allocas: Found alloca use that needs bounds:   store [16 x i32] addrspace(200)* %slot_src, [16 x i32] addrspace(200)* addrspace(200)* %slot_leak, align 16
; DBG-NEXT: cheri-bound-allocas: store_stack_to_other_slot: 1 of 1 users need bounds for   %slot_src = alloca [16 x i32], align 4, addrspace(200)
; DBG-NEXT: store_stack_to_other_slot: setting bounds on stack alloca to 64  %slot_src = alloca [16 x i32], align 4, addrspace(200)
; DBG-NEXT: cheri-bound-allocas:  -Checking if load/store needs bounds (GEP offset is 0):   %leaked_value = load [16 x i32] addrspace(200)*, [16 x i32] addrspace(200)* addrspace(200)* %slot_leak, align 16
; DBG-NEXT: cheri-bound-allocas:   -Load/store size=16, alloca size=16, current GEP offset=0 for [16 x i32] addrspace(200)*
; DBG-NEXT: cheri-bound-allocas:   -Load/store is in bounds -> can reuse $csp for   %leaked_value = load [16 x i32] addrspace(200)*, [16 x i32] addrspace(200)* addrspace(200)* %slot_leak, align 16
; DBG-NEXT: cheri-bound-allocas:  -Checking if load/store needs bounds (GEP offset is 0):   store [16 x i32] addrspace(200)* %2, [16 x i32] addrspace(200)* addrspace(200)* %slot_leak, align 16
; DBG-NEXT: cheri-bound-allocas:   -Load/store size=16, alloca size=16, current GEP offset=0 for [16 x i32] addrspace(200)*
; DBG-NEXT: cheri-bound-allocas:   -Load/store is in bounds -> can reuse $csp for   store [16 x i32] addrspace(200)* %2, [16 x i32] addrspace(200)* addrspace(200)* %slot_leak, align 16
; DBG-NEXT: cheri-bound-allocas: store_stack_to_other_slot: 0 of 2 users need bounds for   %slot_leak = alloca [16 x i32] addrspace(200)*, align 16, addrspace(200)
; DBG-NEXT: cheri-bound-allocas: No need to set bounds on stack alloca  %slot_leak = alloca [16 x i32] addrspace(200)*, align 16, addrspace(200)

define i8 addrspace(200)* @store_stack_to_other_slot_with_offset() addrspace(200) nounwind {
; CHECK-LABEL: @store_stack_to_other_slot_with_offset(
; CHECK-NEXT:  entry:
; CHECK-NEXT:    [[X:%.*]] = alloca [16 x i32], align 4, addrspace(200)
; CHECK-NEXT:    [[TMP0:%.*]] = bitcast [16 x i32] addrspace(200)* [[X]] to i8 addrspace(200)*
; CHECK-NEXT:    [[TMP1:%.*]] = call i8 addrspace(200)* @llvm.cheri.bounded.stack.cap.i64(i8 addrspace(200)* [[TMP0]], i64 64)
; CHECK-NEXT:    [[TMP2:%.*]] = bitcast i8 addrspace(200)* [[TMP1]] to [16 x i32] addrspace(200)*
; CHECK-NEXT:    [[X_I8:%.*]] = bitcast [16 x i32] addrspace(200)* [[TMP2]] to i8 addrspace(200)*
; CHECK-NEXT:    [[X_PLUS_4:%.*]] = getelementptr inbounds i8, i8 addrspace(200)* [[X_I8]], i32 4
; CHECK-NEXT:    [[SLOT_LEAK:%.*]] = alloca i8 addrspace(200)*, align 16, addrspace(200)
; CHECK-NEXT:    store i8 addrspace(200)* [[X_PLUS_4]], i8 addrspace(200)* addrspace(200)* [[SLOT_LEAK]], align 16
; CHECK-NEXT:    [[LEAKED_VALUE:%.*]] = load i8 addrspace(200)*, i8 addrspace(200)* addrspace(200)* [[SLOT_LEAK]], align 16
; CHECK-NEXT:    ret i8 addrspace(200)* [[LEAKED_VALUE]]
;
entry:
  %x = alloca [16 x i32], align 4, addrspace(200)
  %x_i8 = bitcast [16 x i32] addrspace(200)* %x to i8 addrspace(200)*
  %x_plus_4 = getelementptr inbounds i8, i8 addrspace(200)* %x_i8, i32 4
  %slot_leak = alloca i8 addrspace(200)*, align 16, addrspace(200)
  store i8 addrspace(200)* %x_plus_4, i8 addrspace(200)* addrspace(200)* %slot_leak, align 16
  %leaked_value = load i8 addrspace(200)*, i8 addrspace(200)* addrspace(200)* %slot_leak, align 16
  ret i8 addrspace(200)* %leaked_value
}

; DBG-LABEL: Checking function store_stack_to_other_slot_with_offset
; DBG-NEXT: cheri-bound-allocas:  -Checking if bitcast needs stack bounds:   %x_i8 = bitcast [16 x i32] addrspace(200)* %x to i8 addrspace(200)*
; DBG-NEXT: cheri-bound-allocas:   -Checking if getelementptr needs stack bounds:   %x_plus_4 = getelementptr inbounds i8, i8 addrspace(200)* %x_i8, i32 4
; DBG-NEXT: cheri-bound-allocas:    -Checking if load/store needs bounds (GEP offset is 4):   store i8 addrspace(200)* %x_plus_4, i8 addrspace(200)* addrspace(200)* %slot_leak, align 16
; DBG-NEXT: cheri-bound-allocas:     -Stack slot used as value and not pointer -> must set bounds
; DBG-NEXT: cheri-bound-allocas:   -Adding stack bounds since getelementptr user needs bounds:   store i8 addrspace(200)* %x_plus_4, i8 addrspace(200)* addrspace(200)* %slot_leak, align 16
; DBG-NEXT: cheri-bound-allocas:  -Adding stack bounds since bitcast user needs bounds:   %x_plus_4 = getelementptr inbounds i8, i8 addrspace(200)* %x_i8, i32 4
; DBG-NEXT: cheri-bound-allocas: Found alloca use that needs bounds:   %x_i8 = bitcast [16 x i32] addrspace(200)* %x to i8 addrspace(200)*
; DBG-NEXT: cheri-bound-allocas: store_stack_to_other_slot_with_offset: 1 of 1 users need bounds for   %x = alloca [16 x i32], align 4, addrspace(200)
; DBG-NEXT: store_stack_to_other_slot_with_offset: setting bounds on stack alloca to 64  %x = alloca [16 x i32], align 4, addrspace(200)
; DBG-NEXT: cheri-bound-allocas:  -Checking if load/store needs bounds (GEP offset is 0):   %leaked_value = load i8 addrspace(200)*, i8 addrspace(200)* addrspace(200)* %slot_leak, align 16
; DBG-NEXT: cheri-bound-allocas:   -Load/store size=16, alloca size=16, current GEP offset=0 for i8 addrspace(200)*
; DBG-NEXT: cheri-bound-allocas:   -Load/store is in bounds -> can reuse $csp for   %leaked_value = load i8 addrspace(200)*, i8 addrspace(200)* addrspace(200)* %slot_leak, align 16
; DBG-NEXT: cheri-bound-allocas:  -Checking if load/store needs bounds (GEP offset is 0):   store i8 addrspace(200)* %x_plus_4, i8 addrspace(200)* addrspace(200)* %slot_leak, align 16
; DBG-NEXT: cheri-bound-allocas:   -Load/store size=16, alloca size=16, current GEP offset=0 for i8 addrspace(200)*
; DBG-NEXT: cheri-bound-allocas:   -Load/store is in bounds -> can reuse $csp for   store i8 addrspace(200)* %x_plus_4, i8 addrspace(200)* addrspace(200)* %slot_leak, align 16
; DBG-NEXT: cheri-bound-allocas: store_stack_to_other_slot_with_offset: 0 of 2 users need bounds for   %slot_leak = alloca i8 addrspace(200)*, align 16, addrspace(200)
; DBG-NEXT: cheri-bound-allocas: No need to set bounds on stack alloca  %slot_leak = alloca i8 addrspace(200)*, align 16, addrspace(200)
