// NOTE: Assertions have been autogenerated by utils/update_cc_test_checks.py
// REQUIRES: mips-registered-target
// RUN: %cheri_purecap_cc1 -DTEST_CAP -Wno-tautological-compare -o - -O2 -emit-llvm %s | FileCheck %s
// RUN: %cheri_purecap_cc1 -DTEST_CAP -Wno-tautological-compare -o - -O2 -S %s | FileCheck %s -check-prefix ASM

// CHECK-LABEL: @is_aligned(
// CHECK-NEXT:  entry:
// CHECK-NEXT:    [[TMP0:%.*]] = tail call i64 @llvm.cheri.cap.address.get.i64(i8 addrspace(200)* [[PTR:%.*]])
// CHECK-NEXT:    [[MASK:%.*]] = add i64 [[ALIGN:%.*]], -1
// CHECK-NEXT:    [[SET_BITS:%.*]] = and i64 [[TMP0]], [[MASK]]
// CHECK-NEXT:    [[IS_ALIGNED:%.*]] = icmp eq i64 [[SET_BITS]], 0
// CHECK-NEXT:    ret i1 [[IS_ALIGNED]]
//
_Bool is_aligned(void *__capability ptr, long align) {
  // ASM-LABEL: is_aligned:
  // ASM:      cgetaddr	$1, $c3
  // ASM-NEXT: daddiu	$2, $4, -1
  // ASM-NEXT: and	$1, $1, $2
  // ASM-NEXT: cjr	$c17
  // ASM-NEXT: sltiu	$2, $1, 1
  return __builtin_is_aligned(ptr, align);
}

// CHECK-LABEL: @align_up(
// CHECK-NEXT:  entry:
// CHECK-NEXT:    [[TMP0:%.*]] = tail call i64 @llvm.cheri.cap.address.get.i64(i8 addrspace(200)* [[PTR:%.*]])
// CHECK-NEXT:    [[MASK:%.*]] = add i64 [[ALIGN:%.*]], -1
// CHECK-NEXT:    [[OVER_BOUNDARY:%.*]] = add i64 [[MASK]], [[TMP0]]
// CHECK-NEXT:    [[NEGATED_MASK:%.*]] = sub i64 0, [[ALIGN]]
// CHECK-NEXT:    [[TMP1:%.*]] = and i64 [[OVER_BOUNDARY]], [[NEGATED_MASK]]
// CHECK-NEXT:    [[TMP2:%.*]] = tail call i8 addrspace(200)* @llvm.cheri.cap.address.set.i64(i8 addrspace(200)* [[PTR]], i64 [[TMP1]])
// CHECK-NEXT:    ret i8 addrspace(200)* [[TMP2]]
//
void *__capability align_up(void *__capability ptr, long align) {
  // ASM-LABEL: align_up:
  // ASM:      cgetaddr	$1, $c3
  // ASM-NEXT: daddu	$1, $4, $1
  // ASM-NEXT: daddiu	$1, $1, -1
  // ASM-NEXT: dnegu	$2, $4
  // ASM-NEXT: and	$1, $1, $2
  // ASM-NEXT: cjr	$c17
  // ASM-NEXT: csetaddr	$c3, $c3, $1
  return __builtin_align_up(ptr, align);
}

// CHECK-LABEL: @align_down(
// CHECK-NEXT:  entry:
// CHECK-NEXT:    [[TMP0:%.*]] = tail call i64 @llvm.cheri.cap.address.get.i64(i8 addrspace(200)* [[PTR:%.*]])
// CHECK-NEXT:    [[NEGATED_MASK:%.*]] = sub i64 0, [[ALIGN:%.*]]
// CHECK-NEXT:    [[TMP1:%.*]] = and i64 [[TMP0]], [[NEGATED_MASK]]
// CHECK-NEXT:    [[TMP2:%.*]] = tail call i8 addrspace(200)* @llvm.cheri.cap.address.set.i64(i8 addrspace(200)* [[PTR]], i64 [[TMP1]])
// CHECK-NEXT:    ret i8 addrspace(200)* [[TMP2]]
//
void *__capability align_down(void *__capability ptr, long align) {
  // ASM-LABEL: align_down:
  // ASM:      cgetaddr	$1, $c3
  // ASM-NEXT: dnegu	$2, $4
  // ASM-NEXT: and	$1, $1, $2
  // ASM-NEXT: cjr	$c17
  // ASM-NEXT: csetaddr	$c3, $c3, $1
  return __builtin_align_down(ptr, align);
}

// Power-of-2 versions

// CHECK-LABEL: @is_p2aligned(
// CHECK-NEXT:  entry:
// CHECK-NEXT:    [[TMP0:%.*]] = tail call i64 @llvm.cheri.cap.address.get.i64(i8 addrspace(200)* [[PTR:%.*]])
// CHECK-NEXT:    [[NOTMASK:%.*]] = shl nsw i64 -1, [[P2ALIGN:%.*]]
// CHECK-NEXT:    [[MASK:%.*]] = xor i64 [[NOTMASK]], -1
// CHECK-NEXT:    [[SET_BITS:%.*]] = and i64 [[TMP0]], [[MASK]]
// CHECK-NEXT:    [[IS_ALIGNED:%.*]] = icmp eq i64 [[SET_BITS]], 0
// CHECK-NEXT:    ret i1 [[IS_ALIGNED]]
//
_Bool is_p2aligned(void *__capability ptr, long p2align) {
  // ASM-LABEL: is_p2aligned:
  // ASM:      cgetaddr	$1, $c3
  // ASM-NEXT: daddiu	$2, $zero, -1
  // ASM-NEXT: dsllv	$3, $2, $4
  // ASM-NEXT: xor	$2, $3, $2
  // ASM-NEXT: and	$1, $1, $2
  // ASM-NEXT: cjr	$c17
  // ASM-NEXT: sltiu	$2, $1, 1
  return __builtin_is_p2aligned(ptr, p2align);
}

// CHECK-LABEL: @p2align_up(
// CHECK-NEXT:  entry:
// CHECK-NEXT:    [[TMP0:%.*]] = tail call i64 @llvm.cheri.cap.address.get.i64(i8 addrspace(200)* [[PTR:%.*]])
// CHECK-NEXT:    [[NOTMASK:%.*]] = shl nsw i64 -1, [[P2ALIGN:%.*]]
// CHECK-NEXT:    [[MASK:%.*]] = xor i64 [[NOTMASK]], -1
// CHECK-NEXT:    [[OVER_BOUNDARY:%.*]] = add i64 [[TMP0]], [[MASK]]
// CHECK-NEXT:    [[TMP1:%.*]] = and i64 [[OVER_BOUNDARY]], [[NOTMASK]]
// CHECK-NEXT:    [[TMP2:%.*]] = tail call i8 addrspace(200)* @llvm.cheri.cap.address.set.i64(i8 addrspace(200)* [[PTR]], i64 [[TMP1]])
// CHECK-NEXT:    ret i8 addrspace(200)* [[TMP2]]
//
void *__capability p2align_up(void *__capability ptr, long p2align) {
  // ASM-LABEL: p2align_up:
  // ASM:      cgetaddr	$1, $c3
  // ASM-NEXT: daddiu	$2, $zero, -1
  // ASM-NEXT: dsllv	$3, $2, $4
  // ASM-NEXT: xor	$2, $3, $2
  // ASM-NEXT: daddu	$1, $1, $2
  // ASM-NEXT: and	$1, $1, $3
  // ASM-NEXT: cjr	$c17
  // ASM-NEXT: csetaddr	$c3, $c3, $1
  return __builtin_p2align_up(ptr, p2align);
}

// CHECK-LABEL: @p2align_down(
// CHECK-NEXT:  entry:
// CHECK-NEXT:    [[TMP0:%.*]] = tail call i64 @llvm.cheri.cap.address.get.i64(i8 addrspace(200)* [[PTR:%.*]])
// CHECK-NEXT:    [[NOTMASK:%.*]] = shl nsw i64 -1, [[P2ALIGN:%.*]]
// CHECK-NEXT:    [[TMP1:%.*]] = and i64 [[TMP0]], [[NOTMASK]]
// CHECK-NEXT:    [[TMP2:%.*]] = tail call i8 addrspace(200)* @llvm.cheri.cap.address.set.i64(i8 addrspace(200)* [[PTR]], i64 [[TMP1]])
// CHECK-NEXT:    ret i8 addrspace(200)* [[TMP2]]
//
void *__capability p2align_down(void *__capability ptr, long p2align) {
  // ASM-LABEL: p2align_down:
  // ASM:      cgetaddr	$1, $c3
  // ASM-NEXT: daddiu	$2, $zero, -1
  // ASM-NEXT: dsllv	$2, $2, $4
  // ASM-NEXT: and	$1, $1, $2
  // ASM-NEXT: cjr	$c17
  // ASM-NEXT: csetaddr	$c3, $c3, $1
  return __builtin_p2align_down(ptr, p2align);
}
