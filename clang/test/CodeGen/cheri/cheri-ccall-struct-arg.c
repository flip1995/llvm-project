// NOTE: Assertions have been autogenerated by utils/update_cc_test_checks.py UTC_ARGS: --function-signature
// RUN: %cheri128_cc1 -o - %s -emit-llvm | FileCheck %s --check-prefix HYBRID
// RUNNOT: %cheri128_purecap_cc1 -o - %s -emit-llvm | FileCheck %s --check-prefix PURECAP

// Test the calling convention used for CCall functions where the first
// "normal" (not c1/c2/v0) argument is a type that needs to be overaligned in
// the parameter array. This used to erroneously add an unwanted padding
// argument, causing the calling convention to differ from the C calling
// convention for the normal arguments. For bare CCall functions this is just
// inefficient, but cheri_invoke and the libcheri CCall vectors rely on the
// calling convention matching in order to leave the normal arguments untouched
// and act as a simple trampoline.

struct cheri_object {
	void * __capability c1;
	void * __capability c2;
};

extern struct cheri_object cls;

struct cap_pair {
	void * __capability first;
	void * __capability second;
};

__attribute__((cheri_ccall))
void cap_pair_function(struct cheri_object, long, struct cap_pair);

// HYBRID-LABEL: define {{[^@]+}}@call_cap_pair_function
// HYBRID-SAME: () [[ATTR0:#.*]] {
// HYBRID-NEXT:  entry:
// HYBRID-NEXT:    [[DOTCOMPOUNDLITERAL:%.*]] = alloca [[STRUCT_CAP_PAIR:%.*]], align 16
// HYBRID-NEXT:    [[TMP0:%.*]] = bitcast %struct.cap_pair* [[DOTCOMPOUNDLITERAL]] to i8*
// HYBRID-NEXT:    call void @llvm.memset.p0i8.i64(i8* align 16 [[TMP0]], i8 0, i64 32, i1 false)
// HYBRID-NEXT:    [[TMP1:%.*]] = load i8 addrspace(200)*, i8 addrspace(200)** getelementptr inbounds ({ i8 addrspace(200)*, i8 addrspace(200)* }, { i8 addrspace(200)*, i8 addrspace(200)* }* bitcast (%struct.cheri_object* @cls to { i8 addrspace(200)*, i8 addrspace(200)* }*), i32 0, i32 0), align 16
// HYBRID-NEXT:    [[TMP2:%.*]] = load i8 addrspace(200)*, i8 addrspace(200)** getelementptr inbounds ({ i8 addrspace(200)*, i8 addrspace(200)* }, { i8 addrspace(200)*, i8 addrspace(200)* }* bitcast (%struct.cheri_object* @cls to { i8 addrspace(200)*, i8 addrspace(200)* }*), i32 0, i32 1), align 16
// HYBRID-NEXT:    [[TMP3:%.*]] = bitcast %struct.cap_pair* [[DOTCOMPOUNDLITERAL]] to { i8 addrspace(200)*, i8 addrspace(200)* }*
// HYBRID-NEXT:    [[TMP4:%.*]] = getelementptr inbounds { i8 addrspace(200)*, i8 addrspace(200)* }, { i8 addrspace(200)*, i8 addrspace(200)* }* [[TMP3]], i32 0, i32 0
// HYBRID-NEXT:    [[TMP5:%.*]] = load i8 addrspace(200)*, i8 addrspace(200)** [[TMP4]], align 16
// HYBRID-NEXT:    [[TMP6:%.*]] = getelementptr inbounds { i8 addrspace(200)*, i8 addrspace(200)* }, { i8 addrspace(200)*, i8 addrspace(200)* }* [[TMP3]], i32 0, i32 1
// HYBRID-NEXT:    [[TMP7:%.*]] = load i8 addrspace(200)*, i8 addrspace(200)** [[TMP6]], align 16
// HYBRID-NEXT:    call chericcallcc void @cap_pair_function(i8 addrspace(200)* inreg [[TMP1]], i8 addrspace(200)* inreg [[TMP2]], i64 signext 0, i8 addrspace(200)* inreg [[TMP5]], i8 addrspace(200)* inreg [[TMP7]])
// HYBRID-NEXT:    ret void
//
void call_cap_pair_function(void) {
	cap_pair_function(cls, 0, (struct cap_pair){0, 0});
}

struct i128_pair {
	__int128 first;
	__int128 second;
};

__attribute__((cheri_ccall))
void i128_pair_function(struct cheri_object, long, struct i128_pair);

// HYBRID-LABEL: define {{[^@]+}}@call_i128_pair_function
// HYBRID-SAME: () [[ATTR0]] {
// HYBRID-NEXT:  entry:
// HYBRID-NEXT:    [[DOTCOMPOUNDLITERAL:%.*]] = alloca [[STRUCT_I128_PAIR:%.*]], align 16
// HYBRID-NEXT:    [[TMP0:%.*]] = bitcast %struct.i128_pair* [[DOTCOMPOUNDLITERAL]] to i8*
// HYBRID-NEXT:    call void @llvm.memset.p0i8.i64(i8* align 16 [[TMP0]], i8 0, i64 32, i1 false)
// HYBRID-NEXT:    [[TMP1:%.*]] = load i8 addrspace(200)*, i8 addrspace(200)** getelementptr inbounds ({ i8 addrspace(200)*, i8 addrspace(200)* }, { i8 addrspace(200)*, i8 addrspace(200)* }* bitcast (%struct.cheri_object* @cls to { i8 addrspace(200)*, i8 addrspace(200)* }*), i32 0, i32 0), align 16
// HYBRID-NEXT:    [[TMP2:%.*]] = load i8 addrspace(200)*, i8 addrspace(200)** getelementptr inbounds ({ i8 addrspace(200)*, i8 addrspace(200)* }, { i8 addrspace(200)*, i8 addrspace(200)* }* bitcast (%struct.cheri_object* @cls to { i8 addrspace(200)*, i8 addrspace(200)* }*), i32 0, i32 1), align 16
// HYBRID-NEXT:    [[TMP3:%.*]] = bitcast %struct.i128_pair* [[DOTCOMPOUNDLITERAL]] to { i64, i64, i64, i64 }*
// HYBRID-NEXT:    [[TMP4:%.*]] = getelementptr inbounds { i64, i64, i64, i64 }, { i64, i64, i64, i64 }* [[TMP3]], i32 0, i32 0
// HYBRID-NEXT:    [[TMP5:%.*]] = load i64, i64* [[TMP4]], align 16
// HYBRID-NEXT:    [[TMP6:%.*]] = getelementptr inbounds { i64, i64, i64, i64 }, { i64, i64, i64, i64 }* [[TMP3]], i32 0, i32 1
// HYBRID-NEXT:    [[TMP7:%.*]] = load i64, i64* [[TMP6]], align 8
// HYBRID-NEXT:    [[TMP8:%.*]] = getelementptr inbounds { i64, i64, i64, i64 }, { i64, i64, i64, i64 }* [[TMP3]], i32 0, i32 2
// HYBRID-NEXT:    [[TMP9:%.*]] = load i64, i64* [[TMP8]], align 16
// HYBRID-NEXT:    [[TMP10:%.*]] = getelementptr inbounds { i64, i64, i64, i64 }, { i64, i64, i64, i64 }* [[TMP3]], i32 0, i32 3
// HYBRID-NEXT:    [[TMP11:%.*]] = load i64, i64* [[TMP10]], align 8
// HYBRID-NEXT:    call chericcallcc void @i128_pair_function(i8 addrspace(200)* inreg [[TMP1]], i8 addrspace(200)* inreg [[TMP2]], i64 signext 0, i64 inreg [[TMP5]], i64 inreg [[TMP7]], i64 inreg [[TMP9]], i64 inreg [[TMP11]])
// HYBRID-NEXT:    ret void
//
void call_i128_pair_function(void) {
	i128_pair_function(cls, 0, (struct i128_pair){0, 0});
}
